# Market Prediction Competition - EDA Report

## 1. ë°ì´í„° ê°œìš”

### ë°ì´í„°ì…‹ êµ¬ì¡°
- **Train set**: 8,991 rows (trading days) Ã— 98 columns
- **Test set**: 11 rows (mock test, ì‹¤ì œ í‰ê°€ì‹œì—ëŠ” ìƒˆë¡œìš´ ë°ì´í„°ë¡œ êµì²´ë¨)
- **ì‹œê°„ ë²”ìœ„**: date_id 0 ~ 8,990 (ìˆ˜ì‹­ë…„ ë¶„ëŸ‰ì˜ ì—­ì‚¬ì  ë°ì´í„°)

### Feature ì¹´í…Œê³ ë¦¬ (ì´ 94ê°œ)
| ì¹´í…Œê³ ë¦¬ | ê°œìˆ˜ | ì„¤ëª… |
|---------|------|------|
| **M** | 18 | Market Dynamics/Technical features - ì‹œì¥ ê¸°ìˆ ì  ì§€í‘œ |
| **E** | 20 | Macro Economic features - ê±°ì‹œê²½ì œ ì§€í‘œ |
| **I** | 9 | Interest Rate features - ê¸ˆë¦¬ ê´€ë ¨ ì§€í‘œ |
| **P** | 13 | Price/Valuation features - ê°€ê²©/ë°¸ë¥˜ì—ì´ì…˜ ì§€í‘œ |
| **V** | 13 | Volatility features - ë³€ë™ì„± ì§€í‘œ |
| **S** | 12 | Sentiment features - ì‹œì¥ ì‹¬ë¦¬ ì§€í‘œ |
| **MOM** | 0 | Momentum features (READMEì— ì–¸ê¸‰ë˜ì—ˆìœ¼ë‚˜ ì‹¤ì œ ë°ì´í„°ì— ì—†ìŒ) |
| **D** | 9 | Dummy/Binary features - ì´ì§„ ì§€í‘œ |

### Target ë³€ìˆ˜ (Train only)
1. **forward_returns**: ë‹¤ìŒë‚  S&P 500 ìˆ˜ìµë¥  (ì˜¤ëŠ˜ ë§¤ìˆ˜ â†’ ë‚´ì¼ ë§¤ë„)
2. **risk_free_rate**: Federal funds rate (ë¬´ìœ„í—˜ ìˆ˜ìµë¥ )
3. **market_forward_excess_returns**:
   - 5ë…„ ë¡¤ë§ í‰ê· ì„ ì œê±°í•œ ì´ˆê³¼ ìˆ˜ìµë¥ 
   - MAD criterion 4ë¡œ winsorizing ì²˜ë¦¬ë¨
   - íŠ¸ë Œë“œê°€ ì œê±°ëœ ìˆ˜ìµë¥ 

### Test set ì¶”ê°€ ì»¬ëŸ¼
- **is_scored**: í‰ê°€ì— í¬í•¨ë˜ëŠ” row ì—¬ë¶€
- **lagged_forward_returns**: 1ì¼ lagëœ ìˆ˜ìµë¥ 
- **lagged_risk_free_rate**: 1ì¼ lagëœ ë¬´ìœ„í—˜ ìˆ˜ìµë¥ 
- **lagged_market_forward_excess_returns**: 1ì¼ lagëœ ì´ˆê³¼ ìˆ˜ìµë¥ 

---

## 2. ì£¼ìš” ë°œê²¬ì‚¬í•­

### 2.1 ê²°ì¸¡ì¹˜ íŒ¨í„´ (ë§¤ìš° ì¤‘ìš”!)

#### ì‹œê°„ì— ë”°ë¥¸ ê²°ì¸¡ì¹˜ ë³€í™”
- **ì´ˆê¸° ê¸°ê°„ (date_id < 1,000)**: í‰ê·  **~85ê°œ feature ê²°ì¸¡** (ì•½ 87% ê²°ì¸¡ë¥ )
- **ìµœê·¼ ê¸°ê°„ (date_id > 8,000)**: í‰ê·  **0ê°œ feature ê²°ì¸¡** (ì™„ì „í•œ ë°ì´í„°)
- **ì¤‘ê°„ ê¸°ê°„**: ì ì§„ì ìœ¼ë¡œ ê²°ì¸¡ë¥  ê°ì†Œ

#### ê²°ì¸¡ì¹˜ íŒ¨í„´ì˜ ì˜ë¯¸
- ê³¼ê±°ë¡œ ê°ˆìˆ˜ë¡ ë°ì´í„° í’ˆì§ˆì´ ë–¨ì–´ì§
- ìµœê·¼ ëª‡ì²œê°œ ë°ì´í„°ëŠ” ëª¨ë“  featureê°€ ì™„ì „í•¨
- **ì´ˆê¸° í¬ì†Œ ë°ì´í„°ëŠ” í•™ìŠµì—ì„œ ì œì™¸í•˜ëŠ” ê²ƒì„ ê¶Œì¥**

#### ì¹´í…Œê³ ë¦¬ë³„ ê²°ì¸¡ì¹˜
ëª¨ë“  feature ì¹´í…Œê³ ë¦¬ê°€ ì´ˆê¸°ì—ëŠ” ë¹„ìŠ·í•œ ê²°ì¸¡ íŒ¨í„´ì„ ë³´ì„. íŠ¹ì • ì¹´í…Œê³ ë¦¬ë§Œ ìœ ë… ê²°ì¸¡ì´ ë§ì€ ê²ƒì€ ì•„ë‹˜.

#### ê¶Œì¥ì‚¬í•­
**date_id >= [ì™„ì „ì„± ê¸°ì¤€ì ]**ë¶€í„°ì˜ ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ì—¬ ì´ˆê¸° ëª¨ë¸ í•™ìŠµ ê¶Œì¥
- ì´ë ‡ê²Œ í•˜ë©´ ì•½ 6,000~7,000ê°œì˜ ì™„ì „í•œ ë°ì´í„° í™•ë³´ ê°€ëŠ¥
- í˜¹ì€ LightGBM/XGBoost ë“± ê²°ì¸¡ì¹˜ë¥¼ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ëª¨ë¸ ì‚¬ìš©

---

### 2.2 íƒ€ê²Ÿ ë³€ìˆ˜ íŠ¹ì„±

#### Forward Returns í†µê³„
```
í‰ê·  ì¼ì¼ ìˆ˜ìµë¥ : ~0.03% (ì–‘ìˆ˜)
í‘œì¤€í¸ì°¨: ~0.012 (1.2%)
ì™œë„(Skewness): ì•½ê°„ ìŒìˆ˜ (ì™¼ìª½ ê¼¬ë¦¬ê°€ ê¸´ ë¶„í¬ - í° í•˜ë½ì´ ê°€ë” ë°œìƒ)
ì²¨ë„(Kurtosis): >3 (Fat tails - ê·¹ë‹¨ê°’ì´ ì •ê·œë¶„í¬ë³´ë‹¤ ë§ìŒ)
```

#### ì—°ê°„í™” ë©”íŠ¸ë¦­ (252 trading days ê¸°ì¤€)
```
ì—°ê°„ ìˆ˜ìµë¥ : ~7-9%
ì—°ê°„ ë³€ë™ì„±: ~18-20%
Sharpe Ratio (raw): ~0.4-0.5
```

#### ì‹œê³„ì—´ íŠ¹ì„±
- **ìê¸°ìƒê´€(Autocorrelation)**: ê±°ì˜ 0ì— ê°€ê¹Œì›€
  - ì¼ì¼ ìˆ˜ìµë¥ ì€ ê±°ì˜ ëœë¤ì›Œí¬ (íš¨ìœ¨ì  ì‹œì¥ ê°€ì„¤ ì§€ì§€)
  - Lag-1 ìƒê´€ê´€ê³„ ë§¤ìš° ì•½í•¨

- **ë³€ë™ì„± í´ëŸ¬ìŠ¤í„°ë§**: ì¡´ì¬í•¨!
  - ì œê³± ìˆ˜ìµë¥ ì˜ ìê¸°ìƒê´€ > 0
  - ë†’ì€ ë³€ë™ì„±ì´ ë†’ì€ ë³€ë™ì„± ë‹¤ìŒì— ì˜¤ëŠ” ê²½í–¥
  - GARCH ê³„ì—´ ëª¨ë¸ ê³ ë ¤ ê°€ëŠ¥

#### ìˆ˜ìµë¥  ë¶„í¬ íŠ¹ì§•
- **ì •ê·œë¶„í¬ ì•„ë‹˜**: Q-Q plotì—ì„œ ë²—ì–´ë‚¨
- **Fat tails**: ê·¹ë‹¨ ì›€ì§ì„ì´ ì •ê·œë¶„í¬ë³´ë‹¤ ë§ìŒ
- **ì•½ê°„ì˜ ìŒì˜ ì™œë„**: í° í•˜ë½ì´ í° ìƒìŠ¹ë³´ë‹¤ ì•½ê°„ ë” ìì£¼ ë°œìƒ

#### ìŠ¹ë¥  í†µê³„
- ì–‘ìˆ˜ ìˆ˜ìµë¥  ì¼ìˆ˜: ~53-55%
- ìŒìˆ˜ ìˆ˜ìµë¥  ì¼ìˆ˜: ~45-47%
- ì¥ê¸°ì ìœ¼ë¡œ ìƒìŠ¹ í¸í–¥

---

### 2.3 ì‹œì¥ Regime ë¶„ì„

4ê°€ì§€ ì‹œì¥ ìƒí™©ìœ¼ë¡œ ë¶„ë¥˜ ê°€ëŠ¥:
1. **Bull-Quiet**: ìƒìŠ¹ + ë‚®ì€ ë³€ë™ì„± (ì´ìƒì )
2. **Bull-Volatile**: ìƒìŠ¹ + ë†’ì€ ë³€ë™ì„±
3. **Bear-Quiet**: í•˜ë½ + ë‚®ì€ ë³€ë™ì„± (ì„œì„œíˆ í•˜ë½)
4. **Bear-Volatile**: í•˜ë½ + ë†’ì€ ë³€ë™ì„± (í­ë½ êµ¬ê°„)

ê° regimeì— ë”°ë¼ ìµœì  allocationì´ ë‹¬ë¼ì§ˆ ê²ƒìœ¼ë¡œ ì˜ˆìƒ:
- Bull-Quiet: ë†’ì€ allocation (1.5-2.0)
- Bull-Volatile: ì¤‘ê°„ allocation (1.0-1.5)
- Bear-Quiet: ë‚®ì€ allocation (0.5-1.0)
- Bear-Volatile: ë§¤ìš° ë‚®ì€ allocation (0-0.5)

---

### 2.4 Feature ì¸ì‚¬ì´íŠ¸

#### Featureì™€ íƒ€ê²Ÿì˜ ìƒê´€ê´€ê³„
- ëŒ€ë¶€ë¶„ì˜ featureê°€ forward_returnsì™€ ì•½í•œ ìƒê´€ê´€ê³„ (|r| < 0.1)
- ì¼ë¶€ featureëŠ” ì¤‘ê°„ ì •ë„ì˜ ìƒê´€ê´€ê³„ ë³´ì„ (|r| ~ 0.1-0.3)
- **ìƒê´€ê´€ê³„ê°€ ê°•í•œ featureê°€ ë§ì§€ ì•ŠìŒ** â†’ ë¹„ì„ í˜• íŒ¨í„´ì„ ì°¾ì•„ì•¼ í•¨

#### Feature ì¹´í…Œê³ ë¦¬ë³„ íŠ¹ì§•
- **M (Market Dynamics)**: ê°€ì¥ ì¦‰ê°ì ì¸ ì‹œì¥ ìƒí™© ë°˜ì˜
- **V (Volatility)**: ë³€ë™ì„± regime íŒŒì•…ì— ì¤‘ìš”
- **E (Economic)**: ì¥ê¸° íŠ¸ë Œë“œì— ì˜í–¥, ë‹¨ê¸° ì˜ˆì¸¡ì—ëŠ” ëœ ìœ ìš©í•  ìˆ˜ ìˆìŒ
- **I (Interest Rate)**: ì‹œì¥ ë°©í–¥ì„±ì— ì˜í–¥
- **S (Sentiment)**: ë‹¨ê¸° ì›€ì§ì„ ì˜ˆì¸¡ì— ìœ ìš©í•  ìˆ˜ ìˆìŒ

#### Feature ê°„ ìƒê´€ê´€ê³„
- ê°™ì€ ì¹´í…Œê³ ë¦¬ ë‚´ì—ì„œ ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ë³´ì´ëŠ” feature ìŒë“¤ì´ ì¡´ì¬
- Feature selectionì´ë‚˜ PCA ê³ ë ¤ ê°€ëŠ¥
- ë‹¤ë§Œ tree-based ëª¨ë¸ì€ ë‹¤ì¤‘ê³µì„ ì„±ì— ê°•í•˜ë¯€ë¡œ í¬ê²Œ ë¬¸ì œë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ

#### Feature ì•ˆì •ì„±
- ëŒ€ë¶€ë¶„ì˜ featureê°€ ì‹œê°„ì— ë”°ë¼ ë¹„ì •ìƒì„±(non-stationarity) ë³´ì„
- Rolling í†µê³„ë‚˜ ì°¨ë¶„(differencing) ê³ ë ¤ í•„ìš”

---

### 2.5 Drawdown ë¶„ì„

- **Maximum Drawdown**: ì•½ -40% ~ -55% (ë°ì´í„° ê¸°ê°„ì— ë”°ë¼ ë‹¤ë¦„)
- ì—¬ëŸ¬ ì°¨ë¡€ì˜ í° í•˜ë½ êµ¬ê°„ ì¡´ì¬
- íšŒë³µ ê¸°ê°„(recovery period)ë„ ìƒë‹¹íˆ ê¸¸ ìˆ˜ ìˆìŒ

**ì „ëµ êµ¬í˜„ì‹œ ê³ ë ¤ì‚¬í•­**:
- Drawdownì„ ì¤„ì´ëŠ” ê²ƒì´ ì¤‘ìš”
- Bear marketì—ì„œ allocationì„ ë‚®ì¶”ëŠ” ê²ƒì´ í•µì‹¬
- ë‹¨ìˆœíˆ ìˆ˜ìµë¥ ë§Œ ë†’ì´ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ risk-adjusted return ìµœì í™”

---

## 3. ëŒ€íšŒ í•´ê²° ì „ëµ

### 3.1 í•µì‹¬ ë„ì „ê³¼ì œ

#### ë¬¸ì œì˜ ë³¸ì§ˆ
ì´ ëŒ€íšŒëŠ” ë‹¨ìˆœí•œ íšŒê·€ ë¬¸ì œê°€ **ì•„ë‹˜**:
- **ëª©í‘œ**: Forward returns ì˜ˆì¸¡ + ìµœì  portfolio allocation ê²°ì •
- **ì œì•½**: ë³€ë™ì„± 120% ì´í•˜ ìœ ì§€
- **ë©”íŠ¸ë¦­**: ì»¤ìŠ¤í…€ Sharpe ratio (volatility & return penalties)

#### ì£¼ìš” ë‚œì œ
1. **Time-series íŠ¹ì„±**: ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€ í•„ìˆ˜
2. **Noisy target**: ì¼ì¼ ìˆ˜ìµë¥ ì€ ë§¤ìš° ë…¸ì´ì¦ˆê°€ ë§ìŒ (autocorr â‰ˆ 0)
3. **Regime dependency**: ì‹œì¥ ìƒí™©ì— ë”°ë¼ ì „ëµì´ ë‹¬ë¼ì ¸ì•¼ í•¨
4. **Volatility constraint**: ê³¼ë„í•œ leverage ì‚¬ìš©ì‹œ íŒ¨ë„í‹°
5. **API ì œí•œ**: 5ë¶„ inference ì œí•œ, 15ë¶„ model loading ì œí•œ

---

### 3.2 ì œì•ˆ ì ‘ê·¼ë²•

#### ì ‘ê·¼ë²• 1: ìˆ˜ìµë¥  ì˜ˆì¸¡ â†’ í• ë‹¹ ë³€í™˜ â˜… (ì¶”ì²œ)

**ì»¨ì…‰**:
- Forward returnsë¥¼ ì˜ˆì¸¡
- ì˜ˆì¸¡ê°’ì„ allocation (0-2)ë¡œ ë§¤í•‘

**ì¥ì **:
- ì§ê´€ì ì´ê³  êµ¬í˜„í•˜ê¸° ì‰¬ì›€
- íšŒê·€ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥
- Feature engineeringì´ ììœ ë¡œì›€

**ë‹¨ì **:
- ì˜ˆì¸¡ â†’ allocation ë§¤í•‘ ê·œì¹™ì´ ëª…í™•í•˜ì§€ ì•ŠìŒ
- Volatility constraintë¥¼ ì§ì ‘ ê³ ë ¤í•˜ì§€ ì•ŠìŒ

**êµ¬í˜„ ë°©ë²•**:
```python
# Step 1: ì˜ˆì¸¡ ëª¨ë¸
predicted_return = model.predict(features)

# Step 2: Allocation ë§¤í•‘
if predicted_return > threshold_high:
    allocation = 1.5  # ë†’ì€ allocation
elif predicted_return > threshold_low:
    allocation = 1.0  # ì¤‘ê°„ allocation
else:
    allocation = 0.5  # ë‚®ì€ allocation

# Step 3: Volatility-based scaling
recent_vol = calculate_recent_volatility()
if recent_vol > vol_threshold:
    allocation *= 0.8  # ë³€ë™ì„± ë†’ì„ë•Œ allocation ì¤„ì„
```

**ì¶”ì²œ ëª¨ë¸**:
- LightGBM (ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ìš°ìˆ˜, ë¹ ë¦„)
- XGBoost (ì•ˆì •ì ì¸ ì„±ëŠ¥)
- CatBoost (robust)

**êµ¬í˜„ ë‚œì´ë„**: â­â­ (ì¤‘í•˜)

---

#### ì ‘ê·¼ë²• 2: ì§ì ‘ í• ë‹¹ íšŒê·€ (Direct Allocation Regression)

**ì»¨ì…‰**:
- Optimal allocationì„ ì§ì ‘ ì˜ˆì¸¡
- Historical dataë¡œ ìµœì  allocation ê³„ì‚° â†’ ì´ë¥¼ targetìœ¼ë¡œ í•™ìŠµ

**ì¥ì **:
- End-to-end í•™ìŠµ
- Metricì— ì§ì ‘ ìµœì í™”

**ë‹¨ì **:
- "ìµœì  allocation"ì„ ì–´ë–»ê²Œ ì •ì˜í•˜ê³  ê³„ì‚°í•  ê²ƒì¸ê°€?
- Backtesting í•„ìš” â†’ ì‹œê°„ ì†Œìš”

**êµ¬í˜„ ë°©ë²•**:
```python
# Step 1: ê° ì‹œì ì˜ ìµœì  allocation ê³„ì‚° (backtest)
for each historical date:
    try different allocations (0, 0.1, 0.2, ..., 2.0)
    calculate forward Sharpe ratio for next N days
    optimal_allocation[date] = allocation with best Sharpe

# Step 2: ëª¨ë¸ í•™ìŠµ
model.train(features, target=optimal_allocation)

# Step 3: ì˜ˆì¸¡
allocation = model.predict(current_features)
```

**ë¬¸ì œì **:
- Optimal allocationì´ ë¯¸ë˜ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ê²Œ ë¨ (look-ahead bias)
- Rolling windowë¡œ ê³„ì‚°í•´ì•¼ í•˜ì§€ë§Œ ë³µì¡í•¨

**êµ¬í˜„ ë‚œì´ë„**: â­â­â­â­ (ìƒ)

---

#### ì ‘ê·¼ë²• 3: ë¶„ë¥˜ ì ‘ê·¼ + Kelly Criterion

**ì»¨ì…‰**:
- ì‹œì¥ ë°©í–¥(ìƒìŠ¹/í•˜ë½) ë¶„ë¥˜
- ì˜ˆì¸¡ í™•ë¥ ì„ Kelly criterionìœ¼ë¡œ allocation ê³„ì‚°

**ì¥ì **:
- ë¶„ë¥˜ ë¬¸ì œë¡œ ë‹¨ìˆœí™”
- Kelly criterionì€ ì´ë¡ ì ìœ¼ë¡œ ìµœì  sizing

**ë‹¨ì **:
- ìˆ˜ìµë¥  í¬ê¸° ì •ë³´ ì†ì‹¤
- Kelly criterionì€ ì •í™•í•œ í™•ë¥  í•„ìš” (calibration ì¤‘ìš”)

**êµ¬í˜„ ë°©ë²•**:
```python
# Step 1: ë¶„ë¥˜ ëª¨ë¸
prob_up = classifier.predict_proba(features)[1]

# Step 2: Kelly criterion
edge = prob_up - 0.5  # ìš°ìœ„
kelly_fraction = edge / volatility

# Step 3: Allocation with constraints
allocation = clip(kelly_fraction * leverage_factor, 0, 2)
```

**êµ¬í˜„ ë‚œì´ë„**: â­â­â­ (ì¤‘ìƒ)

---

#### ì ‘ê·¼ë²• 4: ì•™ìƒë¸” ì „ëµ â˜…â˜… (ìµœì¢… ì¶”ì²œ)

**ì»¨ì…‰**:
- ì—¬ëŸ¬ ì „ëµì„ ê²°í•©
- Historical performanceë¡œ ê°€ì¤‘ í‰ê· 

**êµ¬ì„±**:
1. **íšŒê·€ ëª¨ë¸**: Returns ì˜ˆì¸¡ (LightGBM, XGBoost)
2. **ë¶„ë¥˜ ëª¨ë¸**: Direction ì˜ˆì¸¡ (Neural Net, LightGBM)
3. **ì‹œê³„ì—´ ëª¨ë¸**: ARIMA, GARCH (ë³€ë™ì„± ì˜ˆì¸¡)
4. **ê¸°ìˆ ì  ì „ëµ**: Momentum, Mean reversion
5. **ë³€ë™ì„± ì¡°ì ˆ**: Dynamic volatility targeting

**ì•™ìƒë¸” ë°©ë²•**:
```python
# ê° ì „ëµì˜ allocation ê³„ì‚°
alloc_1 = regression_strategy()
alloc_2 = classification_strategy()
alloc_3 = momentum_strategy()
alloc_4 = volatility_strategy()

# ê°€ì¤‘ í‰ê·  (weightsëŠ” validation performance ê¸°ë°˜)
final_allocation = (
    w1 * alloc_1 +
    w2 * alloc_2 +
    w3 * alloc_3 +
    w4 * alloc_4
)

# Volatility constraint ì²´í¬
if predicted_strategy_vol > 1.2 * market_vol:
    final_allocation *= scaling_factor
```

**ì¥ì **:
- Robust (ë‹¨ì¼ ëª¨ë¸ ì‹¤íŒ¨í•´ë„ ê´œì°®ìŒ)
- ë‹¤ì–‘í•œ ì‹œì¥ regimeì— ì ì‘ ê°€ëŠ¥
- Best performance ê°€ëŠ¥ì„±

**ë‹¨ì **:
- ë³µì¡í•¨
- ê°œë°œ ì‹œê°„ ì˜¤ë˜ ê±¸ë¦¼
- Overfitting ìœ„í—˜

**êµ¬í˜„ ë‚œì´ë„**: â­â­â­â­â­ (ìµœìƒ)

---

### 3.3 Feature Engineering ì•„ì´ë””ì–´

#### 1. Lag Features
```python
for feature in all_features:
    for lag in [1, 5, 20, 60]:
        df[f'{feature}_lag{lag}'] = df[feature].shift(lag)
```

**ì´ìœ **:
- ì¼ì¼ ìˆ˜ìµë¥ ì€ noisyí•˜ì§€ë§Œ ê³¼ê±° feature íŒ¨í„´ì€ ìœ ìš©í•  ìˆ˜ ìˆìŒ
- íŠ¹íˆ 5ì¼, 20ì¼ lagëŠ” ì£¼ê°„/ì›”ê°„ íŒ¨í„´ í¬ì°©

#### 2. Rolling Statistics
```python
windows = [5, 10, 20, 60]
for feature in all_features:
    for window in windows:
        df[f'{feature}_mean_{window}'] = df[feature].rolling(window).mean()
        df[f'{feature}_std_{window}'] = df[feature].rolling(window).std()
        df[f'{feature}_min_{window}'] = df[feature].rolling(window).min()
        df[f'{feature}_max_{window}'] = df[feature].rolling(window).max()
```

**ì´ìœ **:
- Noise ì œê±°
- Trendì™€ volatility í¬ì°©

#### 3. Momentum Indicators
```python
# Returns-based momentum
df['momentum_5'] = df['forward_returns'].rolling(5).sum()
df['momentum_20'] = df['forward_returns'].rolling(20).sum()

# Feature-based momentum
for feature in all_features:
    df[f'{feature}_momentum'] = df[feature] - df[feature].shift(20)
    df[f'{feature}_roc'] = (df[feature] / df[feature].shift(20)) - 1  # Rate of change
```

#### 4. Volatility Features
```python
# Historical volatility
df['vol_5'] = df['forward_returns'].rolling(5).std()
df['vol_20'] = df['forward_returns'].rolling(20).std()
df['vol_60'] = df['forward_returns'].rolling(60).std()

# Volatility of volatility
df['vol_of_vol'] = df['vol_20'].rolling(20).std()

# Volatility regime
df['vol_regime'] = (df['vol_20'] > df['vol_20'].rolling(60).mean()).astype(int)
```

#### 5. Market Regime Features
```python
# Returns regime
df['bull_market'] = (df['forward_returns'].rolling(60).mean() > 0).astype(int)

# Volatility regime
vol_percentile = df['vol_20'].rolling(252).rank(pct=True)
df['low_vol_regime'] = (vol_percentile < 0.33).astype(int)
df['high_vol_regime'] = (vol_percentile > 0.67).astype(int)
```

#### 6. Cross-sectional Features
```python
# Feature correlations
df['M_mean'] = df[[c for c in df.columns if c.startswith('M')]].mean(axis=1)
df['V_mean'] = df[[c for c in df.columns if c.startswith('V')]].mean(axis=1)

# Feature dispersion
df['feature_std'] = df[all_features].std(axis=1)
```

#### 7. Missing Value Features
```python
# Missing value indicators can be informative!
df['n_missing'] = df[all_features].isnull().sum(axis=1)
df['missing_pct'] = df['n_missing'] / len(all_features)

for feature in all_features:
    df[f'{feature}_is_missing'] = df[feature].isnull().astype(int)
```

#### 8. Target Encoding (ì£¼ì˜!)
```python
# ONLY use past information (walk-forward)
# DO NOT use global mean (data leakage!)

# Example: Safe target encoding
def safe_target_encode(df, feature, target, window=100):
    # For each row, use only past 100 rows to compute mean
    encoding = df.groupby(feature)[target].apply(
        lambda x: x.shift(1).rolling(window=window, min_periods=10).mean()
    )
    return encoding
```

---

### 3.4 ëª¨ë¸ í›„ë³´

#### Tier 1: ë¹ ë¥¸ í”„ë¡œí† íƒ€ì…ìš© (ì¼ì£¼ì¼ ë‚´ êµ¬í˜„)

1. **LightGBM** â­â­â­â­â­
   - **ì¶”ì²œ ì´ìœ **:
     - ê²°ì¸¡ì¹˜ ìë™ ì²˜ë¦¬
     - ë¹ ë¥¸ í•™ìŠµ
     - ë¹„ì„ í˜• íŒ¨í„´ í¬ì°© ìš°ìˆ˜
     - Kaggleì—ì„œ ê²€ì¦ëœ ì„±ëŠ¥
   - **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ í¬ì¸íŠ¸**:
     - `num_leaves`: 31-127
     - `learning_rate`: 0.01-0.1
     - `min_data_in_leaf`: 20-100
     - `feature_fraction`: 0.7-0.9

2. **XGBoost** â­â­â­â­
   - **ì¶”ì²œ ì´ìœ **:
     - ë§¤ìš° ì•ˆì •ì 
     - Regularization ìš°ìˆ˜
     - ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ê°€ëŠ¥
   - **í•˜ì´í¼íŒŒë¼ë¯¸í„°**:
     - `max_depth`: 3-7
     - `eta`: 0.01-0.1
     - `colsample_bytree`: 0.7-0.9

3. **Ridge/Lasso Regression** â­â­â­
   - **ì¶”ì²œ ì´ìœ **:
     - ë¹ ë¥¸ baseline
     - ê³¼ì í•© ìœ„í—˜ ë‚®ìŒ
     - Interpretability ìš°ìˆ˜
   - **ë‹¨ì **: ë¹„ì„ í˜• íŒ¨í„´ í¬ì°© ì–´ë ¤ì›€

#### Tier 2: ì„±ëŠ¥ ê°œì„ ìš© (2-3ì£¼ íˆ¬ì)

4. **Random Forest** â­â­â­â­
   - ì•™ìƒë¸”ì— í¬í•¨ì‹œí‚¤ê¸° ì¢‹ìŒ
   - LightGBMê³¼ ë‹¤ë¥¸ íŒ¨í„´ í•™ìŠµ

5. **Neural Networks** â­â­â­
   - MLP, LSTM, Transformer ê³ ë ¤
   - ë³µì¡í•œ ë¹„ì„ í˜• íŒ¨í„´ í•™ìŠµ ê°€ëŠ¥
   - **ì£¼ì˜**: Overfitting ì¡°ì‹¬
   - **ì¶”ì²œ êµ¬ì¡°**:
     ```
     Input -> Dense(256) -> Dropout(0.3) -> Dense(128) -> Dropout(0.3) -> Output
     ```

6. **TabNet** â­â­â­
   - Attention mechanism for tabular data
   - Feature importance ì œê³µ

#### Tier 3: ì‹¤í—˜ìš© (ì„ íƒì )

7. **GARCH Models**
   - ë³€ë™ì„± ì˜ˆì¸¡ì— íŠ¹í™”
   - Returns ì˜ˆì¸¡ë³´ë‹¤ëŠ” volatility targetingì— ì‚¬ìš©

8. **Reinforcement Learning** â­â­
   - Portfolio optimizationì— ì´ë¡ ì ìœ¼ë¡œ ì í•©
   - í•˜ì§€ë§Œ êµ¬í˜„ ë³µì¡, sample efficiency ë‚®ìŒ
   - ì‹œê°„ ì—¬ìœ  ìˆì„ ë•Œë§Œ ì‹œë„

---

### 3.5 Validation ì „ëµ

#### Walk-Forward Validation (í•„ìˆ˜!)

```python
# DO NOT use random split - data leakage!
# DO NOT use standard K-fold - data leakage!

# Use time-based split
def walk_forward_validation(df, n_splits=5):
    total_len = len(df)
    split_size = total_len // (n_splits + 1)

    for i in range(n_splits):
        train_end = (i + 2) * split_size
        val_start = train_end
        val_end = val_start + split_size

        train_data = df.iloc[:train_end]
        val_data = df.iloc[val_start:val_end]

        yield train_data, val_data
```

#### Purging & Embargo (ì¤‘ìš”!)

```python
# Purge: validation ì§ì „ ë°ì´í„° ì œê±° (label leakage ë°©ì§€)
# Embargo: validation ì´í›„ ë°ì´í„°ë„ trainì—ì„œ ì œê±° (information leakage ë°©ì§€)

def purged_walk_forward(df, n_splits=5, purge_days=5, embargo_days=5):
    for train_data, val_data in walk_forward_validation(df, n_splits):
        # Remove purge period before validation
        train_data = train_data.iloc[:-purge_days]

        # Remove embargo period after validation from NEXT train
        # (ì‹¤ì œë¡œëŠ” ë‹¤ìŒ foldì—ì„œ ì²˜ë¦¬)

        yield train_data, val_data
```

#### Evaluation Metrics

**Primary Metric**: Competition score (êµ¬í˜„ëœ ë©”íŠ¸ë¦­ í•¨ìˆ˜ ì‚¬ìš©)

**Secondary Metrics**:
- Sharpe ratio
- Max drawdown
- Win rate
- Volatility ratio
- Calmar ratio

---

### 3.6 Volatility Constraint ê´€ë¦¬

#### ë°©ë²• 1: Dynamic Scaling

```python
# ì „ëµ volatilityê°€ 120% ë„˜ìœ¼ë©´ allocationì„ ì¤„ì„
def apply_volatility_constraint(allocation, returns, market_vol):
    strategy_vol = calculate_strategy_volatility(allocation, returns)
    vol_ratio = strategy_vol / market_vol

    if vol_ratio > 1.2:
        # Scale down allocation
        scaling_factor = 1.2 / vol_ratio
        allocation *= scaling_factor

    return allocation
```

#### ë°©ë²• 2: Rolling Volatility Targeting

```python
# ì¼ì •í•œ target volatility ìœ ì§€
def volatility_targeting(allocation, target_vol=0.18):
    recent_vol = calculate_recent_volatility(window=20)

    if recent_vol > 0:
        vol_scalar = target_vol / recent_vol
        allocation *= vol_scalar

    # Clip to valid range
    allocation = np.clip(allocation, 0, 2)
    return allocation
```

#### ë°©ë²• 3: Regime-based Adjustment

```python
# ë³€ë™ì„± regimeì— ë”°ë¼ allocation ì¡°ì •
def regime_based_allocation(base_allocation, vol_regime):
    if vol_regime == 'high':
        return base_allocation * 0.7  # ë³€ë™ì„± ë†’ì„ë•Œ ì¤„ì„
    elif vol_regime == 'low':
        return base_allocation * 1.2  # ë³€ë™ì„± ë‚®ì„ë•Œ ëŠ˜ë¦¼
    else:
        return base_allocation
```

---

## 4. êµ¬í˜„ ë¡œë“œë§µ

### Phase 1: ë¹ ë¥¸ ë² ì´ìŠ¤ë¼ì¸ (3-5ì¼)

**ëª©í‘œ**: ì œì¶œ ê°€ëŠ¥í•œ working solution ë§Œë“¤ê¸°

**Tasks**:
1. âœ… Data loading & EDA
2. ë°ì´í„° ì „ì²˜ë¦¬
   - ì™„ì „í•œ ë°ì´í„°ë§Œ ì„ íƒ (date_id > threshold)
   - Feature ì •ê·œí™”/ìŠ¤ì¼€ì¼ë§
3. ê°„ë‹¨í•œ feature engineering
   - Lag features (1, 5, 20)
   - Rolling means (5, 20)
4. LightGBM ëª¨ë¸ í•™ìŠµ
   - Walk-forward validation
   - Hyperparameter tuning (ê°„ë‹¨í•œ grid search)
5. API submission êµ¬í˜„
   - `predict` í•¨ìˆ˜ ì‘ì„±
   - Allocation ë§¤í•‘ ë¡œì§
6. ì²« ì œì¶œ!

**ì˜ˆìƒ ì„±ëŠ¥**: Baseline ëŒ€ë¹„ 10-20% ê°œì„ 

---

### Phase 2: Feature Engineering & ëª¨ë¸ ê°œì„  (1ì£¼)

**ëª©í‘œ**: Feature ìµœì í™” ë° ë‹¤ì–‘í•œ ëª¨ë¸ ì‹¤í—˜

**Tasks**:
1. ê³ ê¸‰ feature engineering
   - ëª¨ë“  lag features
   - Rolling statistics (mean, std, min, max)
   - Volatility features
   - Momentum indicators
   - Market regime features
2. Feature selection
   - Correlation analysis
   - Feature importance (from tree models)
   - Remove redundant features
3. ì¶”ê°€ ëª¨ë¸ ì‹¤í—˜
   - XGBoost
   - CatBoost
   - Random Forest
   - Neural Network (MLP)
4. Hyperparameter optimization
   - Optuna ì‚¬ìš©
   - Walk-forward validationìœ¼ë¡œ í‰ê°€

**ì˜ˆìƒ ì„±ëŠ¥**: Baseline ëŒ€ë¹„ 30-50% ê°œì„ 

---

### Phase 3: ì•™ìƒë¸” & ìµœì í™” (1ì£¼)

**ëª©í‘œ**: ì—¬ëŸ¬ ëª¨ë¸ ê²°í•© ë° metric ìµœì í™”

**Tasks**:
1. Ensemble êµ¬í˜„
   - Weighted average of multiple models
   - Stacking
2. Volatility constraint ìµœì í™”
   - Dynamic scaling
   - Volatility targeting
3. Allocation mapping ìµœì í™”
   - ë‹¤ì–‘í•œ threshold ì‹¤í—˜
   - Non-linear mapping ì‹œë„
4. Metric-specific optimization
   - Sharpe ratio ìµœì í™”
   - Penalty ìµœì†Œí™” ì „ëµ
5. Backtesting
   - ë‹¤ì–‘í•œ ê¸°ê°„ì—ì„œ í…ŒìŠ¤íŠ¸
   - Regimeë³„ ì„±ëŠ¥ ë¶„ì„

**ì˜ˆìƒ ì„±ëŠ¥**: Top 10-20% ëª©í‘œ

---

### Phase 4: ìµœì¢… íŠœë‹ (3-5ì¼)

**ëª©í‘œ**: ë§ˆì§€ë§‰ ì„±ëŠ¥ ì••ì¶• ë° ì•ˆì •ì„± í™•ë³´

**Tasks**:
1. ëª¨ë¸ ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ìµœì í™”
2. ê·¹ë‹¨ ìƒí™© ëŒ€ì‘ ì „ëµ
3. API ì‘ë‹µ ì‹œê°„ ìµœì í™” (5ë¶„ ì œí•œ ì¤€ìˆ˜)
4. Cross-validation ê²°ê³¼ ë¶„ì„
5. ìµœì¢… ì œì¶œ

**ì˜ˆìƒ ì„±ëŠ¥**: Top 5-10% ë„ì „

---

## 5. ì£¼ìš” ìœ„í—˜ ìš”ì†Œ ë° ëŒ€ì‘

### ìœ„í—˜ 1: ë°ì´í„° ëˆ„ìˆ˜ (Data Leakage)

**ìœ„í—˜ë„**: ğŸ”´ ë§¤ìš° ë†’ìŒ

**ì˜ˆì‹œ**:
- ë¯¸ë˜ ë°ì´í„°ë¡œ feature ê³„ì‚°
- Global statistics ì‚¬ìš© (ì „ì²´ ë°ì´í„°ì˜ mean/std)
- Target encodingì‹œ ì „ì²´ ë°ì´í„° ì‚¬ìš©

**ëŒ€ì‘**:
- Walk-forward validation ì—„ê²©íˆ ì¤€ìˆ˜
- Feature ê³„ì‚°ì‹œ í•­ìƒ `.shift(1)` ì‚¬ìš©
- Rolling statisticsë§Œ ì‚¬ìš©

### ìœ„í—˜ 2: Overfitting

**ìœ„í—˜ë„**: ğŸŸ¡ ë†’ìŒ

**ì›ì¸**:
- ë„ˆë¬´ ë§ì€ feature
- ë³µì¡í•œ ëª¨ë¸
- Hyperparameter ê³¼ë„í•˜ê²Œ íŠœë‹

**ëŒ€ì‘**:
- Regularization (L1, L2, dropout)
- Early stopping
- Simple models ì„ í˜¸
- Feature selection

### ìœ„í—˜ 3: Regime Change

**ìœ„í—˜ë„**: ğŸŸ¡ ì¤‘ê°„

**ë¬¸ì œ**:
- ìµœê·¼ ë°ì´í„°ë¡œ í•™ìŠµí•œ ëª¨ë¸ì´ ë¯¸ë˜ì— ì‘ë™ ì•ˆ í•  ìˆ˜ ìˆìŒ
- ì‹œì¥ regimeì´ ë°”ë€Œë©´ ì „ëµ ì‹¤íŒ¨

**ëŒ€ì‘**:
- ë‹¤ì–‘í•œ regimeì—ì„œ validation
- Robust features ì„ íƒ
- ì•™ìƒë¸”ë¡œ ë‹¤ì–‘ì„± í™•ë³´

### ìœ„í—˜ 4: Volatility Penalty

**ìœ„í—˜ë„**: ğŸŸ¡ ì¤‘ê°„

**ë¬¸ì œ**:
- Leverage ê³¼ë„í•˜ê²Œ ì‚¬ìš©ì‹œ í° íŒ¨ë„í‹°
- 120% threshold ë„˜ê¸°ë©´ ì ìˆ˜ ê¸‰ë½

**ëŒ€ì‘**:
- Dynamic volatility scaling
- Conservative allocation
- Validationì—ì„œ vol ratio ëª¨ë‹ˆí„°ë§

### ìœ„í—˜ 5: API ì‹œê°„ ì œí•œ

**ìœ„í—˜ë„**: ğŸŸ¢ ë‚®ìŒ

**ì œí•œ**:
- Model loading: 15ë¶„
- Batch inference: 5ë¶„

**ëŒ€ì‘**:
- ëª¨ë¸ í¬ê¸° ìµœì†Œí™”
- Polars ì‚¬ìš© (Pandasë³´ë‹¤ ë¹ ë¦„)
- Feature ê³„ì‚° ìµœì í™”
- ì‚¬ì „ ê³„ì‚° ê°€ëŠ¥í•œ ê²ƒë“¤ pre-compute

---

## 6. ì½”ë“œ êµ¬ì¡° ì œì•ˆ

```
market-prediction/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ test.csv
â”‚   â””â”€â”€ kaggle_evaluation/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ eda.ipynb                 # âœ… Done
â”‚   â”œâ”€â”€ feature_engineering.ipynb
â”‚   â”œâ”€â”€ model_experiments.ipynb
â”‚   â””â”€â”€ ensemble.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ features.py              # Feature engineering functions
â”‚   â”œâ”€â”€ models.py                # Model definitions
â”‚   â”œâ”€â”€ validation.py            # Walk-forward validation
â”‚   â”œâ”€â”€ metric.py                # Competition metric
â”‚   â””â”€â”€ utils.py                 # Utility functions
â”œâ”€â”€ submissions/
â”‚   â”œâ”€â”€ baseline_submission.py
â”‚   â”œâ”€â”€ lgb_submission.py
â”‚   â””â”€â”€ ensemble_submission.py
â”œâ”€â”€ models/
â”‚   â””â”€â”€ trained_models/          # Saved models
â”œâ”€â”€ eda.md                        # âœ… Done
â”œâ”€â”€ knowledge.md                  # Project knowledge
â””â”€â”€ README.md                     # âœ… Done
```

---

## 7. ì°¸ê³  ìë£Œ ë° í•™ìŠµ ë¦¬ì†ŒìŠ¤

### ê´€ë ¨ Competition
- Numerai (ë¹„ìŠ·í•œ í˜•íƒœì˜ ê¸ˆìœµ ì˜ˆì¸¡ ëŒ€íšŒ)
- Jane Street Market Prediction
- Two Sigma competitions

### ìœ ìš©í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
- **Modeling**: LightGBM, XGBoost, scikit-learn
- **Data**: Polars (faster than pandas), pandas
- **Validation**: scikit-learn, custom walk-forward
- **Hyperparameter tuning**: Optuna
- **Visualization**: matplotlib, seaborn, plotly

### ì´ë¡ ì  ë°°ê²½
- **Sharpe Ratio**: ìœ„í—˜ ëŒ€ë¹„ ìˆ˜ìµë¥  ì¸¡ì •
- **Kelly Criterion**: ìµœì  í¬ì§€ì…˜ sizing
- **GARCH Models**: ë³€ë™ì„± ëª¨ë¸ë§
- **Walk-Forward Analysis**: Time series validation

---

## 8. ë‹¤ìŒ ì¦‰ì‹œ í•  ì¼ (Next Steps)

### 1ìˆœìœ„ (ì§€ê¸ˆ ë°”ë¡œ ì‹œì‘) ğŸš€

1. **ë°ì´í„° ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±**
   - ê²°ì¸¡ì¹˜ ì²˜ë¦¬
   - Train/Validation split
   - Feature normalization

2. **ê°„ë‹¨í•œ feature engineering**
   - Lag features (1, 5, 20)
   - Rolling means
   - Volatility features

3. **LightGBM ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸**
   - Walk-forward validation êµ¬í˜„
   - ì²« ì˜ˆì¸¡ ë§Œë“¤ê¸°

4. **API submission êµ¬í˜„**
   - `predict` í•¨ìˆ˜
   - Allocation mapping
   - Local test

### 2ìˆœìœ„ (ë² ì´ìŠ¤ë¼ì¸ ì™„ì„± í›„)

5. **ê³ ê¸‰ feature engineering**
6. **Multiple models ì‹¤í—˜**
7. **Ensemble êµ¬í˜„**

---

## 9. ì„±ê³µ ê¸°ì¤€

### Minimum Goal (ë°˜ë“œì‹œ ë‹¬ì„±)
- âœ… EDA ì™„ë£Œ
- ì‘ë™í•˜ëŠ” submission ì™„ì„±
- Baseline (always 100% invested) ëŒ€ë¹„ ê°œì„ 
- Validation Sharpe ratio > 0.5

### Target Goal (ëª©í‘œ)
- Validation Sharpe ratio > 1.0
- Volatility ratio < 1.15 (ì•ˆì „ ë§ˆì§„)
- Public LB top 30%
- Private LB top 20%

### Stretch Goal (ìµœê³  ëª©í‘œ)
- Public LB top 10%
- Private LB top 10%
- ì—¬ëŸ¬ regimeì—ì„œ ì¼ê´€ëœ ì„±ëŠ¥

---

## 10. ë§ˆë¬´ë¦¬ ë° í•µì‹¬ ì¸ì‚¬ì´íŠ¸

### ğŸ”‘ í•µì‹¬ êµí›ˆ

1. **ì´ ëŒ€íšŒëŠ” ì˜ˆì¸¡ + ìµœì í™” ë¬¸ì œë‹¤**
   - ë‹¨ìˆœíˆ returnsë¥¼ ì˜ ì˜ˆì¸¡í•˜ëŠ” ê²ƒìœ¼ë¡œ ë¶€ì¡±
   - Volatility managementê°€ í•µì‹¬
   - Sharpe ratio ìµœì í™”ê°€ ëª©í‘œ

2. **ë°ì´í„°ê°€ ê¹¨ë—í•˜ì§€ ì•Šë‹¤**
   - ì´ˆê¸° ë°ì´í„° í¬ì†Œ
   - ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì „ëµ í•„ìˆ˜
   - ìµœê·¼ ë°ì´í„° í™œìš© ê¶Œì¥

3. **ì‹œê³„ì—´ íŠ¹ì„± ì¤€ìˆ˜**
   - ë°ì´í„° ëˆ„ìˆ˜ ì¡°ì‹¬
   - Walk-forward validation í•„ìˆ˜
   - Featureë„ ì‹œê°„ ì˜ì¡´ì 

4. **ê°„ë‹¨í•œ ê²ƒë¶€í„° ì‹œì‘**
   - ë³µì¡í•œ ëª¨ë¸ë³´ë‹¤ íƒ„íƒ„í•œ feature
   - ë¹ ë¥¸ iterationì´ ì¤‘ìš”
   - Overfitting ì¡°ì‹¬

### ğŸ’¡ ì„±ê³µì„ ìœ„í•œ íŒ

- **Daily returnsëŠ” noisy** â†’ Rolling statistics í™œìš©
- **Volatility clustering exists** â†’ Volatility prediction ì¤‘ìš”
- **Market regime matters** â†’ Regime-based strategy
- **Ensemble is powerful** â†’ ë‹¤ì–‘í•œ ëª¨ë¸ ê²°í•©
- **Validation is crucial** â†’ ì‹œê°„ ê¸°ë°˜ split ì—„ìˆ˜

### ğŸ¯ ì§‘ì¤‘í•  ì˜ì—­

1. **Feature Engineering** (40% ì‹œê°„)
2. **Validation Strategy** (30% ì‹œê°„)
3. **Model Selection & Tuning** (20% ì‹œê°„)
4. **Ensemble & Optimization** (10% ì‹œê°„)

---

**Ready to code! ğŸš€**
